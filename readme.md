# Sistemas Distribuidos y Paralelos
## Entregable 3
### Juan Manuel Ramallo 954/1
***
## - Ejercicio 1

  **1.1 Enunciado**

  *Realizar un algoritmo MPI que resuelva la expresio패n: 洧 = 洧녬팬洧냢洧냣洧냤 + 洧녪팬洧냥洧냦洧냧, donde A, B, C, D, E y F son matrices de NxN. d팬 y b팬 son los promedios de los valores de los elementos de las matrices D y B, respectivamente.
  Evaluar N=512, 1024 y 2048.*

  **1.2 Resoluci칩n**

  - Primero que nada para mayor legibilidad y poder entender mejor el flujo del programa, se separan las acciones que deben ejecutar el proceso root, o maestro, de los procesos workers.

  - El programa empieza enviando los datos necesarios a todos los procesos disponibles para realizar los c치lculos necesarios.

  - Las multiplicaciones de matrices se realizan en paralelos con todos los procesos disponibles, para lo cual antes se debi칩 haber enviado una matriz completa y la segunda matriz en porciones usando el `MPI_Scatter`.


  **1.3 M칠tricas**

  - A continuaci칩n se pueden observar las mediciones tomadas en las computadoras del aula de postgrado.

  ![medidas-1](Mediciones/Ejercicio_1.png)

  - El principio de localidad hace que la ejecuci칩n en dos m치quinas con la misma cantidad de procesos sea mejor que con una sola, cada m치quina poseer치 los accesos a memoria requeridos por el programa, en posiciones contiguas de memoria.


## - Ejercicio 2

  **2.1 Enunciado**

  *Paralelizar con MPI un algoritmo que ordene un vector de N elementos por mezcla.*

  **2.2 Resoluci칩n**

  - Para mantener el codigo de la funci칩n principal m치s limpio, al igual que en el ejercicio 1 se separan las instrucciones que ejecutan el root y los workers en distintas funciones.

  - El root se encarga de generar el arreglo de N elementos con M como n칰mero m치ximo entre los numeros que contendr치 el arreglo (N y M son par치metros del main)

  - Lo primero que hace el root es distribuir el arreglo entre todos los procesos
  - Luego cada proceso (incluyendo el root) ordena su porci칩n del arreglo

  - Luego cada proceso con ID impar y el 칰ltimo, env칤a su porci칩n ordenada y libera la memoria

  - A su vez, todos los procesos con ID par reciben los datos enviados de los impares para hacer de nuevo una ordenaci칩n por mezcla.

  - El root, al final de la ejecuci칩n, recibe todas las porciones y las ordena

  **2.3 M칠tricas**

  - Seg칰n la eficiencia vista, para una sola m치quina los procesadores pasan m치s del 80% del tiempo realizando trabajo 칰til.
  - Para dos m치quinas, se ve como decrece la eficiencia, debido a que se introduce demasiado tiempo de comunicaci칩n.

  ![medidas-2](Mediciones/Ejercicio_2.png)

## - Ejercicio 3

  **3.1 Enunciado**

  *Paralelizar con MPI un algoritmo que dado un vector de nu패meros enteros encuentre los 100 elementos ma패s frecuentes.*

  **3.2 Resoluci칩n**

  - Se hace uso de una estructura para almacenar las cuentas de cada n칰mero que aparece en el arreglo a buscar.

  - La estructura (Counter) est치 compuesta por dos n칰meros enteros, uno que representa el n칰mero encontrado y el otro que representa la cantidad de veces que apareci칩 ese n칰mero en el arreglo.

  - Se implement칩 una funci칩n `agregar_ordenado` que agrega la cuenta de un n칰mero en un arreglo pasado como par치metro por referencia y ordena el arreglo luego de agregar, al final retorna el tama침o del arreglo; recibe los par치metros:

    - Arreglo de `Counters`
    - Numero a agregar
    - Cuenta a incrementar
    - Tama침o del arreglo de cuentas


  - El root inicializa el arreglo con N elementos con M como n칰mero m치ximo dentro del arreglo

  - El root reparte porciones iguales del arreglo entre todos los procesos

  - Cada proceso (incluyendo el root) cuenta las apariciones de cada n칰mero en su porci칩n y las guarda en un arreglo de `Counters`

  - Luego se une las cuentas con el root de la misma forma que con el ejercicio anterior se unieron las ordenaciones.

  - Los procesos con ID impares env칤an sus cuentas y terminan, mientras los procesos pares agregan las cuentas hasta que al final env칤an sus cuentas al root, el cual las espera y las agrega.

  **3.3 M칠tricas**

  Al observar como var칤a el speedup para un mismo `n칰mero m치ximo` variando el tama침o del arreglo se puede observar que el speedup aumenta, por lo tanto se puede afirmar que al aumentar el tama침o del problema el rendimiento de la ejecuci칩n del programa mejora.

  ![medidas-3](Mediciones/Ejercicio_3.png)
